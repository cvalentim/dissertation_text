\documentclass[12pt,letterpaper]{article}

\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{graphicx}

\usepackage{color}
\usepackage{ulem}


\begin{document}


%\usepackage{amsmath, amsthm, amssymb}
%\usepackage[dvips]{graphicx}
%\usepackage{epsf}

\renewcommand{\baselinestretch}{1.5}
%   \usepackage{latexsym}


\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{property}{Property}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{fact}{Fact}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newcommand{\DT}{ $D$ }
\newcommand{\azul}[1]{\textcolor{blue}{#1}}

\title{A data structure for managing financial time series}

\medskip

\normalsize

 \author{Eduardo S. Laber$^1$ \and David Sotelo \and Caio Valentim \\
 laber@inf.puc-rio.br dsilva@inf.puc-rio.br kakaio9@gmail.com  \\
1- Departamento de Inform\' atica, PUC-Rio }


\date{}
%\institute{ Departamento de Inform\' atica, PUC-Rio, Brazil.
% \email{$\{$laber,milidiu,artur$\}$@inf.puc-rio.br}}

\maketitle

\date{}


% If we apply the test $t_i$ on the object  $o_j$, we either have
%$t_i(o_j)=false$ 
% $o_i$ is applied  

\begin{abstract}
\end{abstract}

\bigskip

 {\bf Keywords: } Data Structures
 

\bigskip



 \section{Introduction}


The study of time series is motivated by applications
that arise in different fields
of human knowledge such as medicine,
physics, meteorology and finance, just to cite a few.
For some applications, involving time series, 
general purpose spreadsheets and databases  provide a good enough solution to analyse them.

However, there are applications in which the time  series are massive
as in the analysis of data
captured by a sensor in a miliseconds basis or in 
the analysis of a series of quotes and trades of  stocks in  an electronic financial market.
For these series, traditional techniques for
storing data may be inadequate due to its time/space consumption.
This scenario motivates the research on
data structures and algorithms to handle massive time series  \cite{conf/vldb/ZhuS02,ShiJaJ05b}.

The focus of our research is to develop data structures that
allow the identification/mining of a certain  type of event in a collection of time series.
We are interested in significant changes  on the time series that
occur in a short time interval.
As an example, let us consider the following situations:

\begin{itemize}

\item Stocks in the financial market can be characterized by their prices  and the volume traded.
Given a collection  of time series, each of them  containing  the price and the volume traded
by a stock, in a second basis, during 10 years,
we want to efficiently handle queries as: 
in which time windows of $k$ seconds,
 most of the stocks had a change  of
 at least $p \%$ in their price and a change of at least $v\%$ in their
 traded volume?
 

\item the prices of two stocks with similar characteristics (e.g. belonging to the same segment of the industry) usually have
a strong correlation.  A very popular trading operation in  financial markets is to
estimate an expected ratio between the prices of two similar stocks
and then bet that the observed ratio will return to the estimated one when it  significantly deviates from it.
To implement this mean reversion operation
one may have to process queries like:
in which time intervals of length $\Delta T$, the ratio between two
stocks varied more than $d \%$?



 

%Meteorologistas estão interessados em estudar padrões
%de mudança de climas em
%certas regiões geográficas.
%Para tal estudo variáveis com temperatura, precipitação e umidade são importantes.
%Dada uma série temporal com tais informações, queremos
%reponder questões como:
%em quais janelas de tempo de $d$ dias  houveram variações de precipitação e temperatura
%acima de um determinado limiar.

\end{itemize}
 
Questions  like those above presented
are asked very often by market analysts and strategy designers 
in financial markets.

\subsection{Problem Definition}

Let $A=(a_1,...,a_n)$ be a
time series with $n$ values.
We use two positive numbers, $t$ and $d$,
to measure  the  variation in the time series $A$ during a  time interval.
We say that a pair of time indexes  $(i,j)$ of $A$ is a $(t,d)$-event if $0<  j-i \leq t$ and $a_j - a_i \geq d$.

We want to design data structures 
to  preprocess/index 
time series so that we can  handle the following  queries in sublinear time:


\begin{itemize}

\item $AllPairs(t,d)$.
This query  returns all $(t,d)$-events.

\item  $Beginning(t,d)$.
This query  returns all  time indexes $i$ such  that there is a time index $j$ for which $(i,j)$ is a $(t,d)$-event.


\end{itemize}

We shall note that it is possible to formulate a  huge number of queries  
related with rapid changes in  a time series so that 
it is hard  to come up with a solution for all of them.
The reason why we  focus on the above queries is because we
believe that they are fundamental queries 
for the study of rapid changes in time series.
In fact, we expect that the techniques we present here 
may  be helpful to address many other queries with the same flavor.


The following notation will be useful for our discussion.
The $\Delta$-value  of a pair $(i,j)$ is given by  $j-i$ and its
deviation is given by $a_j-a_i$.
We say that $i$ is  the startpoint of a pair $(i,j)$  while $j$ is its endpoint.



%We start this line of investigation by considering
%one time series rather than a collection of them.

\subsection{Our Contributions}
To appreciate our contributions it is
useful to first discuss some
potential approaches for handling our queries.

Let $V$ be a vector of  real entries, indexed from $1$ to $n$.
A range minimum(maximum) query (RMQ) over $V$,  with input range $[i,j]$, returns the index  of
the entry of $V$ with minimum(maximum) value,
among those with indexes in the range $[i,j]$.
This  type of query is
very well understood  by the computational geometry community \cite{}.
In fact, it is known  data 
 structures of size $O(n)$ that
support RMQ's in constant time.
 
A  crucial observation is that
the queries $AllPairs(t,d)$ and $Beginning(t,d)$ can be translated into 
multiple RMQ's (details are given in the next section).
Thus, by using data structutes
that support RMQ's, one can  handle  both queries  in 
$O(n+k)$ time,  where $k$ is the size of the  solution set. 
This is an optimal time bound for the offline problem,  where the time spent in 
the preprocessing phase is taken into account to evaluate the query elapsed time.

When the time required for the  preprocessing phase is not taken into account, it is possible to perform much better.
  As an example, for  the query
 $AllPairs(t,d)$, we can achieve sublinear time by storing  
all pairs $\{(i,j) | i < j \}$,
sorted by increasing order of their $\Delta$-values, 
in a data structure that supports
RMQ's.   Though this approach
is very efficient in terms of querying time,
its space
consumption could be prohibitive
for some practical applications 
since we have to store
$\theta(n^2)$ pairs.

The key idea of our approach is to index
a set of specials pairs of
time indexes
rather than all possible pairs.
We say that a pair of time indexes $(i,j)$  is {\em special} with respect to time series
$A$ if the following conditions hold: $i < j$,
$a_i < \min \{a_{i+1},\ldots,a_j\}$ and
$a_j > \max\{a_{i},\ldots,a_{j-1}\}$.

%We show that it is enough to index the special pairs of series $A$
%in order to handle our queries efficiently.


Let $S$ be the set of special pairs of the time series $A$.
We propose a data structure
of size $O(|S|)$ that
handles
query $AllPairs(t,d)$ in $O(\log n + k)$ time,
where $k$ is the the size of the solution set.
On the other hand,  for the query $Beginning(t,d)$,
we propose a structure
of size $O(|S| \log |S|)$ that
provides $ O( f (\log f+\log t)  + k )$ query time,
where $f$ is the number of
distinct time indexes that
are endpoints of special pairs that are $(t,d)$-events.


The main drawback of our approach is that our  data structures
may have quadratic space in the worst case.
This happens, as an example, if the time series is an increasing sequence.
However, we argue that this is not likely to occur.
First, we prove that 
the expected number of special pairs of a random permutation of $\{1,\ldots,n\}$, is  $O(n)$ with high probability.
This result is interesting because the number of special pairs of a time series is equal to the number of special pairs 
of the permutation of  $\{1,\ldots,n\}$ in which
the time series  can be naturally mapped on.
In addition, we perform a number of experiments with
time  series consisting of  stock values 
sampled in a minute basis from the Brazilian stock market.
We compare ...
Our experiments suggest ...








\subsection{Related Work}

The Range Minimum(Maximum) Query (RMQ) problem consists
of preprocessing a given input array such that the position of the minimum (maximum)
between two indexes can be obtained efficiently. 

The first linear time preprocessing and constant time query solution for the RMQ
problem was discovered by Tarjan et. al \cite{Bender00thelca} \cite{Fischer06}. Their algorithm, while a huge improvement
from the theoritical side, was difficult to implement. After this paper,
some others were published proposing some simpler strategies, but they were still
too complex. A work from Bender et al.\cite{Bender00thelca} proposed the first uncomplicated solution
for the RMQ problem based on the connection between the RMQ and the Lowest Commum Ancestor (LCA) problem,
this algorithm  has linear preprocessing time as well as constant query time and is
relatively simple to implement. A work by Fischer and Heun\cite{Fischer06} improves the 
solution by Bender et al. by reducing constants in the memory and time consumption.
This last paper also provides some experiments comparing their algorithm with the one 
from Bender and with another one of linear time preprocessing and logarithmic query time. 
As it turned out, the logarithmic query time algorithm showed better performance on their experiment
compared with the others of constant query time. Based on this report we used the logarithmic query time algorithm for some
of our experiments, since it showed better results and has low memory consumption. 
We also used an algorithm based on dynamic programming with preprocessing time $O(n \log n)$ and $O(1)$
query time, for more information on this strategy see \cite{Bender00thelca}.


A considerable amount of  research has been conducted on  data mining over time series in  the last years as thoroughly discussed in a
 recent survey by \cite{Fu11}. An important research sub-field pointed out by this survey asks for 
how to identify representative information to be used as a similarity measure between two or more time series.
The queries $AllPairs(t,d)$ and $Beginning(t,d)$, proposed in the present paper, try to take a step further in this direction.
The book by Shasha and Zhu \cite{ShaZhu04} reviews some data structures used for indexing  time series --
data reduction and burst detection, among other application, are discussed
The work from Shi and Jaja \cite{ShiJaja03} introduced a framework for exploring temporal patterns of a set of objects.
Their queries are also related to the orthogonal range search problem, and can be used for answering interesting questions involving time series,
but have a flavor considerable different from ours.

Finally, our problem has some similarities to a classical computational geometry problem,
named the fixed-radius near neighbor problem.
This problem consists of, given a set of points $n$ in a $m$-dimensional Euclidean space and a distance $d$, one should report
all pairs of points within distance not greater than $d$. Bentley et al \cite{Ben77} introduced an algorithm that reports all $k$
pairs that honor this property in $O(3^{m}n + k)$. The same approach can be applied if a set $\{d_1, d_2, \ldots,d_n\}$ of maximum distances
is given, one for each dimension. However, it is not clear for us
if similar ideas can be applied to generate all pairs within distance {\it not less} than $d$
or, as in the case of our problem, not greater than $d_1$ in the first dimension and not less than $d_2$ in the second.



\subsection{Paper Organization}
In Section ...



\section{Data Strucutures for Detecting Events in Time Series}
In this section, we explain our approach
to process
the queries $AllPairs(t,d)$ and
$Beginning(t,d)$.

We start our discussion
by presenting observations/results
that are useful to handle both queries.

Our first observation is that 
it is easy to find all $(t,d)$-events that
have a given time index $i$ as a starting point.
For that, we need a  data structure  that supports
range maximum queries over the input $A$. Having
this data structure in hands, we call the  procedure
{\tt GenEventStart}, presented in Figure \ref{fig:GenEvents},
with parameters $(i,i+1,i+t)$.
This procedure, when executed with parameters $(i,low,high)$, generates all 
$(t,d)$-events  with startpoint $i$ and
with endpoint in the range $[low,high]$.
First the procedure uses the data structure to find  the time index $j$  with maximum value  in the 
range  $[low,high]$ of vector $A$. If the deviation of $(i,j)$ is smaller than $d$ then the search is aborted because 
there are no $(t,d)$-events that satisfy  the required conditions. Otherwise,
it reports $(i,j)$ and recurses on intervals $[low,j-1]$ and $[j+1,high]$.

We shall note that there  exists an analogous procedure,
which we call {\tt GenEventsEnd}, that generates 
all $(t,d)$ events that have a given $j$ as an endpoint and
startpoints in the range
$(low,high)$.
We can state the following result.

\begin{proposition}
Let $k$ be the number 
of $(t,d)$-events
that have
startpoint $i$
and endpoint in the range
$[low,high]$.
The Procedure 
{\tt GenEventsStart}(i,low,high) generates
all these $(t,d)$-events
in $O(k)$ time.
\end{proposition}


\begin{figure}

\fbox {

\begin{minipage}{13 cm}

{\tt GenEventsStart}(i,low,high)
  
\hspace{1cm}  {\bf If} $high \geq low$
  
\hspace{2cm}  $j \leftarrow RMQ(low,high)$
  
\hspace{2cm}  {\bf If} $a_j -a_i \geq d$
    
\hspace{3cm}     Add $(i,j)$ to the list of $(t,d)$-events
     
\hspace{3cm}     {\tt GenEventsStart}(low,j-1)
     
\hspace{3cm}     {\tt GenEventsStart}(j+1,high)
   
\hspace{2cm}  {\bf End If  } 

\hspace{1cm} {\bf   End If }

\end{minipage}

}

\caption{Procedure to generate $(t,d)$-events that have a given startpoint}
\label{fig:GenEvents}
\end{figure}






The following  lemma motivates the focus on the 
special pairs in order to handle queries $AllPairs(t,d)$ and
$Beginning(t,d)$.



\begin{lemma}
Let $(i,j)$ be a $(t,d)$-event.
Then, the following  conditions hold

\begin{itemize}
\item[i] there is an index
$i^*$ such that $(i^*,j)$ is a $(t,d)$-event 
 and $i^*$ is the beginning of a special
pair that is also a  $(t,d)$-event.

\item[ii] 
there is an index
$j^*$ such that $(i,j^*)$ is a $(t,d)$-event 
 and $j^*$ is the end of a special
pair that is also a  $(t,d)$-event.
\end{itemize}
\label{lem:SpecialPairsProperty}
\end{lemma}
\begin{proof}
We just need to prove (i) because the proof for
(ii) is analogous.

Let $i^*$ be the time index of the element of $A$  with minimum value among those with time indexes in the set $\{i,\ldots,j-1\}$.
In case of ties, we consider the largest index.
Because $a_{i^*} \leq a_i$ and $(i,j)$ is a $(t,d)$-event,  we have that $(i^*,j)$ is also a $(t,d)$-event.
Let $k^*$ be the time index of the element of $A$  
with maximum value among those with time indexes in the set  $ \{ i^*+1 , \ldots, j\}$.
The pair $( i^*,k^* )$ is both a special pair and a $(t,d)$-event,
which establishes (i).
\end{proof}



\subsection{The Query AllPairs}
Our  solution 
 stores all special pairs $\{(i,j)\}$, sorted by increasing order of $\Delta$-values, in a vector
 $V$. It employs an auxiliary data structure
  ${\cal D}$ of size $O(|S|)$ to support range maximum queries over $V$, using the  deviation of special pairs as the
 search key.
In addition, it employs two auxiliary data structures 
${\cal D}_{min}$ and ${\cal D}_{max}$ of size $O(n)$
to    support, respectively, range minimum and range maximum queries over  $A$.


To handle the query $AllPairs(t,d)$, 
we execute two phases.
In the first one,
we retrieve the endpoints of all special pairs
that are $(t,d)$-events from $V$.
Then, in the second phase, we use these endpoints and the
structures ${\cal D}_{min}$ and ${\cal D}_{max}$ 
to retrieve the $(t,d)$-events.
The two phases are detailed below.

\medskip
\noindent {\bf Phase 1.}
First,
we perform a binary search on vector $V$ to
find the time index $k^*$ of the last pair in $V$  
among those  with $\Delta$-value 
 at most $t$.

Next, we use ${\cal D}$ to perform a set of maximum range queries  to find the 
endpoints of the $(t,d)$-events in $V[1,..,k^*]$.
These endpoints are stored in a list $E_f$.
In fact, let $i$ be the index of
$V$ returned by  a range maximum query over $V$ with input range $[1,k^*]$.
If the deviation of the pair  stored in $V[i]$
is smaller  than $d$ we abort
the search because no other pair in
$V[1,..,k^*]$ has deviation larger than $d$.
Otherwise,
we add the endpoint of this pair to the  list
$E_f$
and we recurse on subvectors $V[1,..,i-1]$ and
$V[i+1,..,k^*]$.
In our process, we use a $0-1$ vector
to verify if a endpoint has already been
added to $E_f$ or not.

At the end of this phase
 the list $E_f$ contains the endpoints of all special pairs that are $(t,d)$-events.
 The complexity of this phase is  $O(|S|)$ because COMPLETAR.


\medskip

\noindent {\bf Phase 2.}
This phase can be split into two
subphases:


\medskip

{\bf Phase 2.1.} In this subphase, we generate all $(t,d)$-events  that
have endpoints in $E_f$.
For that, we call {\tt GenEventsEnd}$(i,i-t,i-1)$ for
every $i \in E_f$.
In this process we keep track of the startpoints of these $(t,d)$-events by storing them 
in a list  $B_f$.
Again, we use a $0-1$ vector to avoid repetitions among
startpoints.

\medskip

{\bf Phase 2.2.}  In this subphase,  we generate  all $(t,d)$-events that have startpoints in $B_f$.
For that, we call {\tt GenEventsStart}$(j,j+1,j+t)$ for
every $j \in B_f$. To verify if a $(t,d)$-event generated at this subphase  is a new one 
we check whether its endpoint belongs to $E_f$ using the same  $0-1$ vector employed at Phase 1.
In the positive case, we ignore
this $(t,d)$-event because it has already been generated at the previous subphase;
otherwise, we add this $(t,d)$ event to the set of  solutions.



%\medskip
%\noindent {\bf Correctness and Time Analysis.}

\begin{theorem}
The above procedure generates all the $k$ solutions of the query $AllPairs(t,d)$  in $O( \log n+ k)$ time
\end{theorem}
\begin{proof}

Let $(i,j)$ be a $(t,d)$-event.
If $j$ is stored in the list  $E_f$ by the end of
 Phase 1, then  $(i,j)$ will be  generated by the of Phase 2.1.

If $j$ is not  stored in the list  $E_f$ byy the end of
Phase 1, let $j^*$ be the endpoint  given by condition (ii) of  Lemma \ref{{lem:SpecialPairsProperty}}.
Since $j^*$ is an endpoint of a special pair that is also a $(t,d)$-event, it follows that $j^*$ will be  stored at the list $E_f$ by the end of Phase 1.
Thus, the startpoint $i$ will be stored at the list
$B_f$ by the end of Phase 2.1 and, as a consequence,  the $(t,d)$-event
$(i,j)$ will be generated by the end of Phase 2.2.
\end{proof}

 

\subsection{The Query Beginning(t,d)}
To explain our approach we need to introduce some notation.
For an interval $[i,j]$, we 
 define $S_{[i,j]}$
 as the set of special pairs  whose $\Delta$-values lie
 in the interval $[i,j]$.
 Let $L_{[i,j]}$ be the
 list obtained as follows:
 first we sort
 the special pairs in $S_{[i,j]}$
 by decreasing order of their deviations.
 Next,  we scan the  list and remove 
 a special pair whenever its endpoint has already appeared as
 an enddpoint of another special pair.
 
To process $Beginning(t,d)$,  we need an ordered
binary tree ${\cal T}$ where each of its nodes is 
associated with a subinterval of $[1,n-1]$.
More precisely, 
the root of ${\cal T}$ is associated with the interval $[1,n-1]$.
If a node $v$ is associated with an interval $[i,..,j]$ then
the left child of $v$
is associated with $[i, \lceil (i+j)/2 \rceil ]$ and its right child is associated with
$[ \lceil (i+j)/2 \rceil +1,j]$.
Furthermore, each node of ${\cal T}$ points to
the list associated with its interval, that is,
if $v$ is  associated with an interval $[i,j]$ then $v$ points
to    $L_{[i,j]}$.
Figure \ref{fig:binary_tree} shows an example for a time series with  $n = 8$ elements.  

%One should observe, from its definition, that an ordered tree ${\cal T}$ of a time series with $n$ elements has height $\lceil \log_{2} (n-1) \rceil + 1$.}

\begin{figure}[htp]
	\begin{center}
		\includegraphics[scale=0.3]{arvore.pdf}
		%\caption{An example of our ordered binary tree}
		\caption{An ordered binary tree for $n = 8$. The root of ${\cal T}$ shall points to the the list $L_{[1,7]}$ while its left and right children have pointers to the lists $L_{[1,4]}$ and $L_{[5,7]}$, respectively.}
		\label{fig:binary_tree}
	\end{center}
\end{figure}


To handle a query  $Beginning(t,d)$
we execute two phases.
In the first phase,
we retrieve the endpoints
of the special pairs that
are $(t,d)$-events.
In the second phase,
we use these
endpoints to retrieve 
 the beginnings of the $(t,d)$-events.
The correctness of this  approach relies on item (ii) of Lemma \ref{lem:SpecialPairsProperty}. 

\medskip

\noindent {\bf Phase 1.}
First, we  find a set $S$ of nodes
in ${\cal T}$
whose associated intervals form a partition of
the interval $[1,t]$.
It can be shown that this partition is unique and it contains at most $\log t$ nodes
\cite{} TEM QUE SER JUSTIFICADO.


Then, for each node $v \in S$ we proceed as  
follows: we scan the list of special pairs associated
with $v$; if the current special pair in our scan has deviation larger than
$d$, we verify wether it has already been added to the list of endpoints $E_f$. 
In the negative case we add it to  $E_f$;
otherwise,  we discard it.
The scan is aborted when a special pair with 
deviation smaller than $d$ is found.
This step spends $O( |E_f| \log t)$ because
each endpoint may appear in at most $\log t$ lists.



\medskip
\noindent {\bf  Phase 2.}
The second phase can be split
into three subphases.
In the first one,
we sort the endpoints in $E_f$;
in the second one we calculate the closest larger predecessor ($clp$)
of each endpoint in $E_f$; finally, in the last one, we generate the desired beginnings.
These subphases are detailed below:


\medskip

\noindent {\bf  Phase 2.1.}
In the first subphase, we  sort the endpoints of $E_f$ in  $O( \min \{n, |E_f| \log |E_f|\})$ time by
using either  a bucket sort or a heapsort algorithm depending whether $|E_f|$ is larger than $n / \log n$ or not.
Let  $e_1 < e_2 <  \ldots < e_f$ be the endpoints in $E_f$ after applying the sorting procedure.

\medskip
\noindent {\bf  Phase 2.2.}
To generate the beginnings   efficiently,
it will be useful to calculate the closest larger predecessor ($clp$) of  each endpoint
$e_j \in E_f$.
For $j=1,\ldots,|E_f|$, we define  $clp(e_j) = e_{i^*}$, where
$i^*= \max \{ i  | e_i \in E_f \mbox{ and }e_i < e_j \mbox{ and } a_{e_i} \geq a_{e_j} \}$.
To guarantee that the $clp$'s are well defined we 
assume that $E_f$ contains an artificial endpoint $e_0$ such that $e_0=0$ and $a_{e_0}=\infty$.
As an example,  let $E_5 = \{ e_1, e_2, e_3, e_4, e_5\}$ be a list of sorted endpoints, where $(e_1, e_2, e_3, e_4, e_5)$
= $(2, 3, 5, 8, 11)$ and  $(a_{e_1}, a_{e_2}, a_{e_3}, a_{e_4}, a_{e_5}) = (8, 5, 7, 6, 4)$.
We have that $clp(e_4)=e_3$ and $clp(e_3)=e_1$.
The $clp$'s can be  calculated in $O(|E_f|)$ time  through the  pseudo-code presented in Figure \ref{fig:clp}.


%\begin{figure}[htbp]
%\centering
%\fbox{
%\begin{minipage}{13 cm}
%\includegraphics{filename}
%\caption{caption}
%\label{label}
%\end{minipage}
%}
%\end{figure}

\begin{figure}

\fbox{

\begin{minipage}{13 cm}

\small

$Q \leftarrow \emptyset $; Add $e_f$ to the tail of queue $Q$.

{\bf  For} $i=f-1 $ downto 0.

\hspace{1cm} $e \leftarrow Q.tail$

\hspace{1cm} {\bf While} $a_e  < a_{ e_i} $

\hspace{2cm} Remove $e$ from $Q$

\hspace{2cm} $clp(e) \leftarrow e_i$ 

\hspace{2cm} $e \leftarrow Q.tail$ 

\hspace{1cm} {\bf End While}

\hspace{1cm} Add $e_i$ to the tail of $Q$.

{\bf End For}

\end{minipage}

} % close fbox

\caption{Procedure to generate the clp's}

\label{fig:clp} 

\normalsize

\end{figure}
%\end{minipage}

\medskip

\noindent {\bf  Phase 2.3.}
To generate the beginnings of the $(t,d)$-events from
the endpoints in $E_f$,
the procedure presented in Figure \ref{fig:beginnings} 
is executed.
The procedure iterates over
all endpoints in $E_f$ and it stores in the variable
$CurrentHigh$ the smallest time index $j$ for which all beginnings larger $j$ have already been generated.
This variable is initialized with value $e_f-1$ because there are no beginnings larger that $e_f-1$.
For each endpoint $e$, the procedure   looks for  new startpoints
in the range  $[ \max\{e_i -t, clp(e_i)\}, CurrentHigh]$.
It does  not look for startpoints in the range $[e_i-t,clp(e_i)]$  because
every startpoint in this range that can  be generated from $e_i$
can be also generated from $clp(e_i)$ while the opposite is not necessarily true.
Indeed, this is the reason why we calculate the $clp$'s -- they avoid to   generate a startpoint more than once.
Next, the variable $CurrrentHigh$ is updated and a new iteration starts.
This subphase can be implemented in $O(|E_f|+k)$ time,
where $k$ is the number of beginnings generated.


\noindent{Correctness}
ARGUMENTAR CORRETUDE




\begin{figure}

\fbox{

\begin{minipage}{13 cm}

\small

CurrentHigh $\leftarrow e_f -1$

{\bf  For} $i=f $ downto 1.

\hspace{1cm} {\tt GenEventsEnd } $(e_i, \max \{e_i -t, clp(e_i)\}, CurrentHigh)$

\hspace{1cm}  CurrentHigh  $\leftarrow  \max \{ e_i -t,  clp(e_i) \} $

{\bf End For}

\end{minipage}

}

\caption{Procedure to generate the beginnings}
\label{fig:beginnings} 
\normalsize

\end{figure}










%For that,
%pick the endpoint
%of $E_f$ with largest value that
%lies in the interval 
%$[e_ie_{i+1}+t








    
 

 




\noindent {\bf Time Complexity.}

 






\subsection{Evaluating the  Number of Special Pairs}

In this section we give bounds on the number of special
pairs.

The number of special pairs of a time series
is at least 0 and at most $n(n-1)/2$,
where the upper bound is reached for increasing series. 
The following proposition shows that the expected  number of special pairs is
$n-H_n$.


\begin{proposition}
Let $S$ be a list of special pairs constructed from a time series taken uniformly at random from a set 
of $n$ elements. Then, the expected size of $S$ is $n - H_n$, where $H_n$ is the $n$-th harmonic number.
\end{proposition}
\begin{proof}

Let $E[X]$ represent the expected size of list $S$ of special pairs.
Furthermore, let $X_{i,j}$ denote a random indicator variable
that stores $1$ if the pair of time indexes $(i,j)$ belongs to $S$ and $0$ otherwise.

From the previous definitions, 
$$E[X] = E[\sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}X_{i,j}].$$

By the linearity of expectation, it follows that:

$$E[\sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}X_{i,j}] = \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} E[X_{i,j}].$$

Since $E[X_{i,j}] = \frac{1}{(j-i+1)(j-i)} = \frac{1}{j-i} - \frac{1}{j-i+1}$, we have:

$$E[X] = \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}
(\frac{1}{j-i} - \frac{1}{j-i+1})
= \sum\limits_{i=1}^{n-1} (1 - \frac{1}{n-i+1})
= n - \sum\limits_{i=1}^{n} \frac{1}{i}  =  n - H_n.$$
\end{proof}

 

 It will be demonstrated now that, with high probability bounds,
the size of $S$ concentrates around its mean value. More precisely, we will estimate now the tail distribution of the random variable $X$,
representing the expected size of a list of special pairs $S$ of a
a time series given by a random permutation from a set 
of $n$ distinct elements.



\begin{proposition}
%Let $c > 0$ be a real number, then $Pr[X \geq c.n] \leq \frac{\log n}{c^2 n}$
Let $c > 0$ be a real number, then $Pr\{X \geq c .n \} \leq \frac{c' \log n}{c^2 n}$,
where $c'$ is a fixed positive constant.
\end{proposition}





\section{Experimental Work} 
In this section we present the experimental work 
we conducted to  evaluate the proposed data structures.
First, we describe experiments for the query  \textit{AllPairs} and then for the 
query  \textit{Beginning}.

We use  $6$  time series obtained
from Brazilian stock market.
The main characteristic of these time series are presented in  Figure Figura~\ref{tamanho-series}.
 

%==========================
% Corrigir grafico
%==========================

%\begin{figure}[!ht]
%\begin{center}
%\includegraphics[height=8.5cm]{SeriesEntregues.pdf}
%\caption{Series 1} 
%\label{fig:prob-defi}
%\end{center}
%\end{figure}
 
 

All the codes were developed in  \verb|C++|, using compiler \verb|o g++ 4.4.3|, with the optimization flag \verb|-O2| activated. 
Our codes were executed in
a  64 bits Intel(R) Core(TM)2 Duo CPU, T6600 @ 2.20GHz, 
with  \verb|3GB| of RAM. 

\subsection{All Pairs}
To evaluate the  data structure 
proposed in Section \ref{}, we
compare it against a solution that
scans the list $A$ and executes 
{\tt GenEventStats} with parameters
$(i,i+1,i+t)$
for each $i \in \{1,\ldots,n-1\}$.

Since both approaches  require  data structures to support
RMQ's, we considered  two possibilities in our investigation.
The first one, namely
 \verb|RMQ Bucket|,
present the best results among those that require linear preprocessing time \cite{}.
The second one, namely \verb|RMQ St|, is reported to be the the fastest one when linear preprocessing time is not required.

Table \ref{pre-real} shows
the cpu time needed to build each data structure (preprocessing time).
We observe that ...



Since we are interested in rare events, we
 focused on queries 
$AllPairs(t,d)$ that  report a reduced number of 
$(t,d)$-events.
For each of the 6 series we executed 9 quries.
The elapsed times are reported 
in Tables~\ref{1-small-random}- \ref{5-small-random}
 









\begin{table}
\footnotesize
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
& & Serie 1 & Serie 2 & Serie 3 & Serie 4 & Serie 5 & Serie 6\\
\hline
& \textbf{Size (n)} & 191672 & 195708 & 142941 & 137257 & 179443 & 177631\\
\hline
& \textbf{\# Special Pairs} & 1386964 & 1305974 & 713019 & 968666 & 853435 & 910915\\
\hline
\multirow{2}{*}{\textbf{Special Pairs}} & space & 118.6 & 111.3 & 66.4 & 83.2 & 78.6 & 82.1\\
& cpu time & 617.135 & 482.167 & 264.001 & 356.84 & 313.852 & 328.672\\
\hline
\multirow{2}{*}{\textbf{RMQBucket}} & space & 7.5 & 7.6 & 5.6 & 5.3 & 7.0 & 6.9 \\
& cpu time & 18.256 & 22.043 & 9.154 & 7.457 & 15.479 & 16.264\\
\hline
\multirow{2}{*}{\textbf{RMQSt}} & space & 58.8 & 59.9 & 43.8 & 42.1 & 54.9 & 54.4\\
& cpu time & 429.415 & 517.824 & 269.665 & 250.911 & 342.497 & 334.736\\
\hline
\end{tabular}
\label{allpairs-pre-real}
\caption{AllPairs - Time (in miliseconds) and space (in Mb megabytes) to preprocess each structure.}
\normalsize

\end{table}


% series reais, tamanho de resposta pequeno.
% Table 1 - Real serie with small output
\begin{table}
\footnotesize
\begin{center}
\input{12_dec/real_joined.tex}
\caption{AllPairs - Real series from 1 to 3}
\label{allpairs-1-3}
\end{center}
\normalsize
\end{table}

\begin{table}
\footnotesize
\begin{center}
\input{12_dec/real_joined2.tex}
\caption{AllPairs - Real series from 4 to 6}
\label{allpairs-4-6}
\end{center}
\normalsize
\end{table}


\subsection{Query Beginning}


\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
                      & Serie 1 & Serie 2 & Serie 3 & Serie 4 & Serie 5 & Serie 6\\
\hline 
 \textbf{Size (n)} & 191672 & 195708 & 142941 & 137257 & 179443 & 177631\\
\hline
\textbf{SpecialPair}  & 6065.59 & 6037.60 & 3385.11 & 4079.29 & 3737.19 & 3968.09\\
\hline 
\textbf{RmqBucket}     & 22.881  & 25.91   & 12.64   & 9.86    & 16.54   & 16.61\\
\hline 
\textbf{RmqSt}        & 496.331 & 612.21  & 310.42  & 286.18  & 396.57  & 379.23\\
\hline
\end{tabular}
\label{beg-pretimes}
\caption{Beginnings - Preprocessing time (miliseconds)}
\end{center}
\normalsize
\end{table}



\begin{table}
\footnotesize
\begin{center}
\input{25_jan/beg_real_joined.tex}
\caption{Beginnings - Real series from 1 to 3}
\label{beg-real-1-3}
\end{center}
\normalsize
\end{table}

\begin{table}
\footnotesize
\begin{center}
\input{25_jan/beg_real_joined2.tex}
\caption{Beginnings - Real series from 4 to 6}
\label{beg-real-4-6}
\end{center}
\normalsize
\end{table}

% Séries Invertidas

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
                      & Serie 1 & Serie 2 & Serie 3 & Serie 4 & Serie 5 & Serie 6\\
\hline 
 \textbf{Size (n)} & 191672 & 195708 & 142941 & 137257 & 179443 & 177631\\
\hline
\textbf{SpecialPair}  & 850356 & 928878 & 482417 & 548780 & 812149 & 720781\\
\hline
\end{tabular}
\label{neg-query-am-spair}
\caption{Beginnings - Amount of special pairs, negative query.}
\normalsize
\end{center}
\end{table}



\begin{table}
\footnotesize
\begin{center}
\input{01_feb/beg_real_joined.tex}
\caption{Beginnings - Real series from 1 to 3 (Negative Query)}
\label{neg-query-beg-1-3}
\end{center}
\normalsize
\end{table}

\begin{table}
\footnotesize
\begin{center}
\input{01_feb/beg_real_joined2.tex}
\caption{Beginnings - Real series from 4 to 6 (Negative Query)}
\label{neg-query-beg-1-3}
\end{center}
\normalsize
\end{table}


\section{Conclusões}

\appendix
\section{Proof of Proposition \ref{}}
\begin{proof}

\noindent Chebyshev's inequality states that if $X$ is a random variable with expectation $E[X]$ and variance $Var[X]$,
then $Pr\{ |X - E[X]| \geq c \} \leq \frac{Var[X]}{c^2}$, for any positive constant $c$ given.
Considering that, by definition,  $Var[X] = E[X^2] - E[X]^2$, and multiplying $c$ by $E[x]$ in the previous inequality, we have
$Pr\{ |X - E[X]| \geq c E[X] \} \leq \frac{E[X^2] - E[X]^2}{c^2 E[X]^2}$.

In order to make use of Chebyshev's inequality it is necessary to determine $E[X]^2$ and  $E[X^2]$.

From Proposition 1, it follows that $E[X]^2 = (n - H_{n})^2$.

By definition, $E[X^2] = E [( \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} X_{i,j})^2]$.
Hence, by the linearity of expectation, $E[X^2] = ( 2 \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}
\sum\limits_{k=i+1}^{n-1} \sum\limits_{l=k+1}^{n} E[X_{i,j} X_{k,l}] ) +
( \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n} E[(X_{i,j})^2] )$.


We proceed now by calculating $E[X^2]$. It can be splitted into six disjoint cases.

In each one of the following cases we assume that the product of every pair  
of random variables $X_{i,j}$ and $X_{k,l}$  is represented by the intersection
of two closed intervals $[i,j]$ and $[k,l]$, where $[i,j] = \{p | i \leq p \leq j \}$
and $[k,l] = \{q | k \leq q \leq l \}$.

Furthermore, by means of an abuse of notation, we assume in each one of the following cases that
the expression $E[X_{i,j} X_{k,l}]$ denotes $\sum\limits_{i}\sum\limits_{j >i}\sum\limits_{k \geq i}\sum\limits_{l > k} E[X_{i,j} X_{k,l}]$, where $[i,j]$ and $[k,l]$ are pairs of intervals belonging to the related case.


{\bf Case 1:} Intervals  $[i, j]$ and $[k, l]$ are identical.

$E[X_{i,j} X_{k,l}] = E[X_{i,j} X_{i,j}] = E[X_{i,j}] = \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}
\frac{1}{(j-i+1)(j-i)} = n - H_n$

\vspace{0.5cm}


{\bf Case 2a:} Intervals  $[i, j]$ and $[k, l]$ are disjoint.

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2}
\sum\limits_{k=j+1}^{n-1} \sum\limits_{l=k+1}^{n} \frac{1}{(j-i+1)(j-i)(l-k+1)(l-k)} = $

$\sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2}  \left[ \frac{1}{(j-i+1)(j-i)}
\left( \sum\limits_{k=j+1}^{n-1} \sum\limits_{l=k+1}^{n} \frac{1}{(l-k+1)(l-k)} \right) \right] =  $

$\sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{(n - j) - H_{(n - j)}} {(j-i+1)(j-i)} 
= \alpha(n) - \beta(n) - \gamma(n)$, where

$\alpha(n) = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{n} {(j-i+1)(j-i)}$,
$\beta(n) = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{j} {(j-i+1)(j-i)}$ and 
$\gamma(n) =  \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{H_{(n - j)}} {(j-i+1)(j-i)}$
%\sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{n-j} {(j-i+1)(j-i)}

Let us first calculate $\alpha(n)$:

$\alpha(n) = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{n} {(j-i+1)(j-i)}
= n^2 - 2n - H_{(n-2)}$

From $\beta(n)$ definiton, it follows that:

$\beta(n) = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{j} {(j-i+1)(j-i)}
= \sum\limits_{i=1}^{n-3} \left( \sum\limits_{j=i+1}^{n-2} \frac{j}{(j-i)} - \frac{j} {(j-i+1)} \right)$

$\beta(n) = \sum\limits_{i=1}^{n-3} \left[ \left( \frac{i+1}{1} +  \frac{i+2}{2} + \ldots + \frac{n-2}{n-i-2} \right)
- \left( \frac{i+1}{2} +  \frac{i+2}{3} + \ldots + \frac{n-2}{n-i-1} \right) \right]$

$\beta(n) = \sum\limits_{i=1}^{n-3} \left[
\frac{i+1}{1}  + \left( \frac{1}{2} +  \frac{1}{3} + \ldots + \frac{1}{n-i-2} \right)
- \frac{n-2}{n-i-1} \right]
= \sum\limits_{i=1}^{n-3} \left( i + H_{(n-2)} - \frac{n-i-2}{n-i-1} \right)$

$\beta(n) = \frac{(n-3)(n-2)}{2} + \sum\limits_{i=1}^{n-3} H_{i} - \sum\limits_{i=2}^{n-2} \frac{n-2}{i}$

$\beta(n) = \frac{n^2}{2} - \Theta(n \log n)$.

Similarly, a tight bound can be determined for $\gamma(n)$:

$\gamma(n) =  \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{H_{(n - j)}} {(j-i+1)(j-i)}
\leq  \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{H_{n}} {(j-i+1)(j-i)}
\leq  n . H(n) = O(n \log n) $

$\gamma(n) =  \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{H_{(n - j)}} {(j-i+1)(j-i)}
\geq  \sum\limits_{i=1}^{\frac{n-2}{2} - 1} \sum\limits_{j=i+1}^{\frac{n-2}{2}} \frac{H_{(n/2)}} {(j-i+1)(j-i)}
\geq  H(n/2) . \left[\frac{n-2}{2} - H_{(n-2)/2} \right] = \Omega(n \log n) $

Therefore, $\gamma(n) = \Theta(n \log n)$.


Returning to the original equation:

$\sum\limits_{i=1}^{n-3} \sum\limits_{j=i+1}^{n-2} \frac{(n - j) - H_{(n - j)}} {(j-i+1)(j-i)} 
= \alpha(n) - \beta(n) - \gamma(n)
\leq  \frac{n^2}{2} + \Theta(n \log n)$

\vspace{0.5cm}

{\bf Case 2b:} Interval $[k, l]$ is a subinterval of $[i, j]$.

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\sum\limits_{l=k+1}^{n-1} \sum\limits_{j=l+1}^{n} \frac{1}{(j-i+1)(j-i)(l-k+1)(l-k)}
\leq  \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\sum\limits_{l=k+1}^{n-1} \sum\limits_{j=l+1}^{n} \frac{1}{(l-k+1)(l-k)(l-k+1)(l-k)}$

$E[X_{i,j} X_{k,l}] \leq\sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\sum\limits_{l=k+1}^{n-1} \sum\limits_{j=l+1}^{n} \frac{1}{(l-k)^4}
\leq n \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\sum\limits_{l=k+1}^{n-1}  \frac{1}{(l-k)^4} $

$E[X_{i,j} X_{k,l}] \leq n \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\left( \displaystyle \int\limits_{k}^{n-2} \! \frac{1}{(l-k)^4} \, \mathrm{d}l \right)
\leq 3n \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2} \frac{1}{k^3} $

$E[X_{i,j} X_{k,l}]  \leq 3n \sum\limits_{i=1}^{n-3}
\left( \displaystyle \int\limits_{i}^{n-3} \! \frac{1}{k^3} \, \mathrm{d}k \right)
\leq 6n \sum\limits_{i=1}^{n-3} \frac{1}{i^2}
 \leq 6n \left( 1 + \displaystyle \int\limits_{1}^{n-4} \! \frac{1}{i^2} \, \mathrm{d}i \right)
 \leq 18n$

\vspace{0.5cm}

{\bf Case 3:} Intersection between intervals $[i, j]$ and $[k, l]$ with no shared extremes.

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-3} \sum\limits_{k=i+1}^{n-2}
\sum\limits_{j=k+1}^{n-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)(j-i)(l-k-1)}$

This sum can be writen as:

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\sum\limits_{k=i+1}^{j-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)(j-i)(l-k-1)}$


Since that $j < l$ and $ l - k < j - i$, we have:

$E[X_{i,j} X_{k,l}] < \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\sum\limits_{k=i+1}^{j-1} \sum\limits_{l=j+1}^{n} \frac{1}{(j-i+1)(j-i)(l-k)(l-k-1)}$

$E[X_{i,j} X_{k,l}] < \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\left[ \frac{1}{(j-i+1)(j-i)}  \left( \sum\limits_{k=i+1}^{j-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-k)(l-k-1)} \right) \right]$

$E[X_{i,j} X_{k,l}] < \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\left[ \frac{1}{(j-i+1)(j-i)}  \sum\limits_{k=i+1}^{j-1} \sum\limits_{l=j+1}^{n}  \left(  \frac{1}{l-k-1} - \frac{1}{l-k}  \right) \right]$

$E[X_{i,j} X_{k,l}] < \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\left[ \frac{1}{(j-i+1)(j-i)}  \sum\limits_{k=i+1}^{j-1}  \left(  \frac{1}{j-k} - \frac{1}{n-k}  \right) \right]$

$E[X_{i,j} X_{k,l}] < \sum\limits_{i=1}^{n-3} \sum\limits_{j=i+2}^{n-1}
\frac{H_{n}}{(j-i+1)(j-i)} $

Therefore, $E[X_{i,j} X_{k,l}] = O(n \log n)$.

\vspace{0.5cm}

{\bf Case 4:} Intersection between intervals $[i, j]$ and $[k, l]$ with $i = k$.

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)(j-i)}$

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \left[ \frac{1}{(j-i)} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)} \right]
\leq \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \frac{1}{(j-i)(j-i+1)}$

Hence, $E[X_{i,j} X_{k,l}] \leq n - H_{n}$.

\vspace{0.5cm}

{\bf Case 5:} Intersection between intervals $[i, j]$ and $[k, l]$ with $j = k$.

$E[X_{i,j} X_{k,l}] = \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)(l-i-1)}
\leq \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \sum\limits_{l=j+1}^{n} \frac{1}{(l-i+1)(l-i)}
$

$E[X_{i,j} X_{k,l}] \leq \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \sum\limits_{l=j+1}^{n} \left( \frac{1}{l-i} - \frac{1}{l-i+1} \right)
\leq \sum\limits_{i=1}^{n-2}
\sum\limits_{j=i+1}^{n-1} \frac{1}{j-i+1}
$

$E[X_{i,j} X_{k,l}] \leq \sum\limits_{i=1}^{n-2} H_{n}$. Therefore, $E[X_{i,j} X_{k,l}] = O(n \log n)$.


{\bf Case 6:} Intersection between intervals $[i, j]$ and $[k, l]$ with $j = l$.

This is identical to case 4. Hence, $E[X_{i,j} X_{k,l}] \leq n - H_{n}$.


\vspace{0.5cm}


Once that all six cases were analised we are able to estimate $E[X^2]$.
First, it is important to observe that, with exception the case 2a, all other cases
are upper bounded by $O(n \log n)$. In the case 2a, in particular,
$E[X_{i,j} X_{k,l}] = \frac{n^2}{2} + \Theta(n \log n)$. Furthermore, by the definition of $E[X^2]$,
with exception the case 1, the results of all other cases must be multiplied by 2.
Therefore, $E[X^2] = n^2+ \Theta(n \log n)$.

Recall that, from Chebyshev's inequality, $Pr\{ |X - E[X]| \geq c E[X] \} \leq \frac{E[X^2] - E[X]^2}{c^2 E[X]^2}$.

Consequently, $Pr\{ X \geq c n \} \leq Pr\{ X \geq c (n - H_{n}) \} = \frac{n^2 + \Theta(n \log n) - (n - H_{n})^2}{c^2 (n - H_{n})^2}$.

Therefore, $Pr\{ X \geq c n \} \leq \frac{c' \log n}{c^2 n}$ where $c'$ is a positive constant.




\end{proof}

\bibliographystyle{plain}
\bibliography{CPM2012}

\end{document}







\begin{figure}
\begin{center}
\input{22_nov/random_s1/joined-tables.tex}
\caption{serie Aleatória 1 - Saídas Grandes}
\label{1-large-random}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\input{22_nov/random_s2/joined-tables.tex}\\
\caption{serie Aleatória 2 - Saídas Grandes}
\label{2-large-random}
\end{center}
\end{figure}
%Table 3 && Table 4 - Random with large output
\begin{figure}
\begin{center}
\input{22_nov/random_s3/joined-tables.tex}
\caption{serie Aleatória 3 - Saídas Grandes}
\label{3-large-random}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\input{22_nov/random_s4/joined-tables.tex} \\
\caption{serie Aleatória 4 - Saídas Grandes}
\label{4-large-random}
\end{center}
\end{figure}
% Table 5 - Random with large output
\begin{figure}
\begin{center}
\input{22_nov/random_s5/joined-tables.tex}\\
\caption{serie Aleatória 5 - Saídas Grandes}
\label{5-large-random}
\end{center}
\end{figure}
\clearpage
\begin{figure}
\begin{center}
\includegraphics{12_dec/random_s1/graphics.eps}
\caption{serie Aleatória 1 - Saídas Pequenas}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{12_dec/random_s2/graphics.eps}
\caption{serie Aleatória 2 - Saídas Pequenas}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{12_dec/random_s3/graphics.eps}
\caption{serie Aleatória 3 - Saídas Pequenas}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{12_dec/random_s4/graphics.eps}
\caption{serie Aleatória 4 - Saídas Pequenas}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{12_dec/random_s5/graphics.eps}
\caption{serie Aleatória 5 - Saídas Pequenas}
\end{center}
\end{figure}



\subsubsection{series Aleatórias}
Relembrando, este corpus consiste de 5 series, com tamanhos variando de $1$MB até $5$MB.
Cada serie é uma permutação gerada aleatoriamente. Na Figura~\ref{pre-random},
temos os tempos que cada estrutura levou para ser criada durante o pré-processamento
e o espaço ocupado por cada estrutura. Note que a quantidade de f-pair e o espaço
ocupado pela serie são aderentes a análise teórica.
\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
& & serie 1 & serie 2 & serie 3 & serie 4 & serie 5 \\
\hline
& \textbf{Tamanho} & 1048576 & 2097152 & 3145728 & 4194304 & 5242880 \\
\hline
& \textbf{Total f-pairs} & 1049258 & 2096726 & 3146401 & 4193473 & 5247841 \\
\hline
\multirow{2}{*}{\textbf{Fpair}} & Espaço & 109.7 & 228 & 336.8 & 444.5 & 574.9\\
& Tempo & 618.336 & 1279.97 & 1976.78 & 2406.85 & 3372.51\\
\hline
\multirow{2}{*}{\textbf{RMQBucket}} & Espaço & 23.2 & 45.1 & 71.8 & 93.5 & 116.8\\
& Tempo & 114.921 & 286.451 & 527.042 & 455.153 & 755.968\\
\hline
\multirow{2}{*}{\textbf{RMQSt}} & Espaço & 248.4 & 560.4 & 840 & 1.16GB & 1.46GB \\
& Tempo & 112.431 & 290.094 & 528.019 & 465.001 & 759.326\\
\hline
\end{tabular}
\caption{Tempo (milesegundos) e espaço(megabytes, ao menos se especificado diferente) de pré-processamento para cada estrutura.}
\label{pre-random}
\end{center}
\end{figure}
Para esse conjunto fizemos dois tipos de experimentos (cada experimento é um conjunto de consultas).
O primeiro contém consultas com poucas respostas até consultas com número de resposta próximo
ao tamanho da serie, já no segundo, escolhemos consultas $(t, d)$ que retornem poucos pares, essas
consultas são o foco principal desse trabalho, uma vez que estamos interessados
em eventos raros. Nas Figuras~\ref{1-large-random} até ~\ref{5-large-random} estão
os tempos reportados para o primeiro experimento e nas Figuras~\ref{1-small-random} até~\ref{5-small-random}
estão as tabelas para o segundo conjunto, de saídas menores. 
O tempo reportado para uma consulta é calculado através de $5$ (cinco) repetições da mesma
consulta, isto é, o tempo de cada repetição é medido em milisegundos e a mediana dos tempos
das repetições é reportada.
Os parâmetros $(t, d)$ para gerar saídas pequenas foram formados da seguinte forma. A primeira pesquisa
foi feita com $t = 4$ e $d = n - 1000$ ($n$ é tamanho da serie) e cada pesquisa subsequente foi formada a partir da anterior somando-se
$200$ ao valor de $t$ e subtraindo $20$ do valor de $d$. Note que para todas as seis series do conjunto foram usados os mesmos
$t$'s e $d$'s, de forma que essa sequência de geração foi escolhida por retornar valores pequenos em todas as series.
Para as saídas grandes, os resultados sugerem que para a \verb|RMQStructure| os tempos são sempre melhores usando a implementação
com pré-processando $O(n \log n)$ para RMQ (RMQST), porém, devido ao consumo de mémoria não é possível
usar essa estrutura com a quinta serie. Já a estrutura f-pair, para as series de $1$ a $4$, se mostra melhor
até um certo tamanho de saída depois começa a ter tempo de resposta pior que a \verb|RMQSt|. Para serie $5$,
ela é melhor em todas as pesquisas. Em outra linha, para as series com saídas menores, nossa estrutura é bastante rápida.
Isto é um ponto positivo, pois, sobre o foco eventos raros, essas são as pesquisas mais interessantes.
Os gráficos apresentados mostram o tamanho da saída no eixo X e os tempos no eixo Y. Para cada estratégia,
além dos pontos, é apresentada a reta que melhor aproxima o conjunto de pontos, formalmente, a reta
que minimiza a soma das distâncias euclidianas dos ponto em relação a ela. Note que essa reta parece modelar
bem o comportamento de cada estratégia. Isto acontece pois como apresentado na parte teórica, o tempo de consulta
para a estratégia RmqSt é linear, para estratégia rmqBucket é $n\log n$ e, o tempo esperado da f-pair é $n\log n$
quando a saída é da ordem do tamanho da serie. Ou seja, os tempos de consultas são ou uma função linear ou uma próxima. 
\begin{figure}
\begin{center}
\includegraphics{22_nov/random_s1/graphics.eps}
\caption{serie Aleatória 1 - Saídas Grandes}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{22_nov/random_s2/graphics.eps}
\caption{serie Aleatória 2 - Saídas Grandes}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{22_nov/random_s3/graphics.eps}
\caption{serie Aleatória 3 - Saídas Grandes}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{22_nov/random_s4/graphics.eps}
\caption{serie Aleatória 4 - Saídas Grandes}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics{22_nov/random_s5/graphics.eps}
\caption{serie Aleatória 5 - Saídas Grandes}
\end{center}
\end{figure}
% Table 1 && Table 2 - Random with small output
\clearpage
\begin{figure}
\begin{center}
\input{12_dec/random_s1/joined-tables.tex}
\caption{serie Aleatória 1 - Saídas Pequenas}
\label{1-small-random}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\input{12_dec/random_s2/joined-tables.tex}\\
\caption{serie Aleatória 2 - Saídas Pequenas}
\label{2-small-random}
\end{center}
\end{figure}
% Table 3 && Table 4 - Random with small output
\begin{figure}
\begin{center}
\input{12_dec/random_s3/joined-tables.tex}
\label{3-small-random}
\caption{serie Aleatória 3 - Saídas Pequenas}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\input{12_dec/random_s4/joined-tables.tex} \\
\label{4-small-random}
\caption{serie Aleatória 4 - Saídas Pequenas}
\end{center}
\end{figure}
% Table 6 - Random with small output
\begin{figure}
\begin{center}
\input{12_dec/random_s5/joined-tables.tex}\\
\caption{serie Aleatória 5 - Saídas Pequenas}
\label{5-small-random}
\end{center}


To understand what happens inside each iteration,
we introduce the concept of domination among
endpoints.
We say that an endpoint $e$ dominates an endpoint $e'$ if the
following conditions hold: $e < e'$ and 
$a_e \geq a_{e'}$. If $e$ dominates $e'$ then all
the beginnings in the range $[1,e-1]$ that can be generated from $e'$ can be also
generated from $e$ so that it is not necessary to keep $e'$ if one is interested to 
generate these beginnings.


At the beginning of the $i$th iteration,  the algorithm  maintains a queue $Q$
containing all endpoints with time indexes in
the range $[e_{i+1},e_{i+1}+t]$ that are not dominated by endpoints in this range. 
This queue is  simultaneously sorted  by decreasing order
of time indexes and decreasing order of  values.
At each iteration of the {\bf While} loop  the
algorithm removes the first endpoint in $Q$ and uses it to generate all
startpoints of $(t,d)$  events that lie in the range $[e_i,CurrentHigh]$.












\begin{figure}

Assumir $e_0=0$


 Add $e_f$ to ${\cal Q}$;
 
 CurrentHigh $\leftarrow e_{f}-1 $
 
 
{\bf  For} $i=f-1 $ downto 0.

\hspace{1cm}   $e \leftarrow $  time index at the top of ${\cal Q}$.

\hspace{1cm}  {\bf  While} $ e - t > e_i$ 
   
\hspace{2cm}	   {\tt GenEventsEnd}(e, e-t, CurrentHigh)
	   
\hspace{2cm}	   Remove $e$ from ${\cal Q}$
	 
\hspace{2cm}	   CurrentHigh $\leftarrow e-t -1 $
	   
\hspace{2cm}	   $e \leftarrow $  time index at the top of ${\cal Q}$.

\hspace{1cm}	{\bf End While }

\hspace{1cm}  {\tt GenEventsEnd}(e, $e_i$, CurrentHigh)

\hspace{1cm}    Add $e_i$ to ${\cal Q}$;  

\hspace{1cm} CurrentHigh $\leftarrow e_{i}-1 $

 \hspace{1cm}   Remove from ${\cal Q}$ all time indexes   with value smaller than that of $e_i$
   
{\bf End For}
\caption{Procedure to generate the beginnings}
\label{fig:beginnings} 
\end{figure}
